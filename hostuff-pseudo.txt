/* 

	Antelope + Hotstuff = Roasted Antelope

	Roasted Antelope is a proposal for an upgrade to the Antelope consensus model, based on the Hotstuff protocol. This document defines extended pseudocode for this upgrade.

	Notes: This pseudocode is based on algorithms 4 (safety) & 5 (liveness) of the "HotStuff: BFT Consensus in the Lens of Blockchain" paper.

	There are a few modifications to the pacemaker algorithm implementation, allowing to decompose the role of block producer into the 3 sub-roles of block proposer, block finalizer and consensus leader. 

	This pseudocode handles each role separately. A single entity may play multiple roles.

	As is the case with the algorithm 4 of the hotstuff paper, the notion of view is almost completely decoupled from the safety protocol, and is aligned to the liveness protocol instead.

	The pseudo code also defines a final_on_qc field as part of a proposal. This field contains another proposal that is guaranteed to be final if the proposal that contains it achieves quorum. 

*/

// Data structures 

//evolved from producer_schedule
schedule(){
	
	//currently, block producers fulfill the roles of block_proposers, block_finalizers and consensus_leaders. A future upgrade can further define the selection process for each of these roles, and result in distinct sets of variable size without compromising the protocol's safety

	block_proposers = [...<block proposers>];

	block_finalizers = [...<block finalizers>];

	consensus_leaders = [...<consensus leaders>];

	current_leader //defined by pacemaker, abstracted [...];
	current_proposer //defined by pacemaker, abstracted [...];

}

//quorum certificate
qc(){

	//digest to sign and unique identifier of proposal
	proposal_id

	//block candidate ID, acts as node message
	block_id

	//phase counter. 0 for prepare, 1 for precommit, 2 for commit, 3 for decide
	phase_counter

	//aggregate signature of finalizers part of this QC
	agg_sig

	//data structure which includes the list of signatories included in the aggregate, (for easy aggregate signature verification)
	sig_bitset

	//get block height from block_id + phase_counter
	get_height() = <block height + phase_counter>; //abstracted [...]

	//check if a quorum of valid signatures (greater or equal to me._threshold) from the active finalizer set has been met
	quorum_met(){
		//return <true or false>; //abstracted [...]
	}

}

//proposal
proposal(){

	//digest to sign and unique identifier of proposal
	proposal_id
	
	//block id, which also encodes the block height
	block_id

	//phase counter. 0 for prepare, 1 for precommit, 2 for commit, 3 for decide
	phase_counter

	//previous proposal, which this proposal extends
	parent

	//QC justification for this proposal
	justify

	//previous proposal that is guaranteed to be final if the current proposal has quorum
	final_on_qc

	//return block height from block_id + phase_counter
	get_height() = <block height + phase_counter>; //abstracted [...];

}

//available msg types
enum msg_type {
	new_view //used when leader rotation is required
	new_block //used when proposer is different from leader
	qc 	//quorum certificate progress
	vote //vote by replicas
}

// Internal book keeping variables

//Hotstuff protocol

me._chained_mode = false; //set to true to revert to chained hotstuff, default is event-driven hotstuff

me._v_height; //height of last voted proposal

me._b_lock; //locked proposal
me._b_exec; //last committed proposal
me._b_leaf; //current proposal

me._high_qc; //highest known QC

//chain data

me._b_storage; //temporary storage of received proposals. Pruning rules (ie: removing committed or stale proposals) are abstracted from the pseudo code

me._schedule //current block producer schedule


//global configuration

me._block_interval; //expected block time interval, default is 0.5 second
me._blocks_per_round; //numbers of blocks per round, default is 12

me._threshold; //configurable quorum threshold


//network_plugin protocol hooks and handlers

//generic network message generation function
network_plugin.new_message(type, ...data){
	
	new_message.type = type;
	new_message[...] = ...data;

	return new_message;
}

network_plugin.broadcast(msg){

	//broadcasting to other nodes, replicas, etc.

	//nodes that are not part of consensus making (not proposer, finalizer or leader) relay consensus messages, but take no action on them

	//abstracted [...] 

}

//on new_block message received event handler (coming from a proposer that is not leader)
network_plugin.on_new_block_received(block){
	
	//abstracted [...] 

	proposal = new_proposal_candidate(block);

	pacemaker.on_beat(proposal); //check if we are leader and need to create a new view for this block

}

//on vote received event handler
network_plugin.on_vote_received(msg){
	
	//abstracted [...] 

	hotstuff.on_vote_received(msg);

}


//Pacemaker algorithm, regulating liveness

//returns the current proposer from the activate schedule
pacemaker.get_proposer(){
	//abstracted [...]
}

//returns the current leader from the activate schedule
pacemaker.get_leader(){
	//abstracted [...]
}

//returns a list of current finalizers from the activate schedule
pacemaker.get_finalizers(){
	//abstracted [...]
}

/*

	on_beat(proposal) is called in the following cases :

	1) As a block proposer, when we generate a proposal
	2) As a consensus leader, when we receive a proposal from a proposer
	3) As a consensus leader, when we complete a quorum certificate on a phase

*/

pacemaker.on_beat(proposal){

	am_i_proposer = get_proposer() == me; //am I proposer?
	am_i_leader = get_leader() == me; //am I leader?

	if (!am_i_proposer && !am_i_leader) return; //replicas that are not the leader nor the proposer don't have to do anything here
	
	//if i'm the leader
	if (am_i_leader){
		
		if (!am_i_proposer){

			//block validation
			//abstracted [...]
			
		}

		me._b_leaf = proposal; 

	}
 	
 	if (am_i_leader) msg = new_message(qc, proposal); //if I'm leader, send QC message
 	else if (am_i_proposer) msg = new_message(new_block, proposal); //if I'm only proposer, send new_block message

	network_plugin.broadcast(msg); //broadcast message

}

//update high QC
pacemaker.update_high_qc(new_high_qc){
	
	// if new high QC is higher than current, update to new
	if (new_high_qc.get_height()>me._high_qc.get_height()){

		me._high_qc = new_high_qc;
		me._b_leaf = me._b_storage.get(me._high_qc.proposal_id);

	} 

}

pacemaker.on_msg_received(msg){

	//p2p message relay logic
	//abstracted [...] 

	if (msg.type == new_view){
		pacemaker.update_high_qc(msg.high_qc);
	}
	else if (msg.type == qc){
		hotstuff.on_proposal_received(msg);
	}
	else if (msg.type == vote){
		hotstuff.on_vote_received(msg);
	}
}


/*

	onNextSyncView

	Corresponds to onNextSyncView in hotstuff paper. Handles both leader rotations as well as timeout if leader fails to progress

	on_leader_rotate() should be called by replicas as early as possible when either :
	 
	1) no more blocks are expected before leader rotation occurs (eg: after receiving the final block expected from the current leader before the handoff) 

	OR

	2) if we reach (me._block_interval * (me._blocks_per_round - 1)) time into a specific view, and we haven't received the expected second to last block for this round. In other words, assuming our _blocks_per_round value is 12, if we haven't received the 11th block by the time at which the 12th is scheduled, our probability of both receiving the 12th block and being able to provide our high_qc to the next leader before the next round begins are very low. Therefore, we can send our high_qc right away.

	In scenarios where liveness is maintained, this relieves an incoming leader from having to wait until it has received n - f new_view messages at the beginning of a new view since it will already have the highest QC.

	In scenarios where liveness has been lost due to f + 1 faulty replicas, progress is impossible, so the safety rule rejects attempts at creating a QC until liveness has been restored. 

*/

//corresponds to condition #2 of onNextSyncView comment
//abstracted [...]
pacemaker.on_round_timeout(){
	
	pacemaker.on_leader_rotate();

}

//called by replicas when it is time to rotate to a new leader. See onNextSyncView
pacemaker.on_leader_rotate(){

	msg = new_message(new_view, me._high_qc); //add highest QC

	network_plugin.broadcast(msg); //broadcast message

}

//on block produced event handler
producer_plugin.on_block_produced(block){
	
	//generate a new block
	//abstracted [...] 

	//Include the highest QC we recorded so far

	block.qc = me._high_qc;

	proposal = new_proposal_candidate(block);

	pacemaker.on_beat(proposal);
	
}


//Hotstuff algorithm, regulating safety

//get the 3-phase QC chain for a given proposal
hotstuff.get_qc_chain(proposal){

	b[];

	b[2] = me._b_storage.get(proposal.justify.proposal_id); //first phase, prepare
	b[1] = me._b_storage.get(b[2].justify.proposal_id); //second phase, precommit
	b[0] = me._b_storage.get(b[1].justify.proposal_id); //third phase, commit

	return b;

}

//new proposal candidate generation
hotstuff.new_proposal_candidate(block) {
	
	//create new proposal b_new

	b_new.parent = me._b_leaf ; //proposal which this new proposal builds upon, or null if no _b_leaf upon activation or chain launch
	b_new.phase_counter = 0;
	b_new.justify = me._high_qc; //or null if no _high_qc upon activation or chain launch
	b_new.block_id = block.header.block_id();

	//we get the 3-phase chain for the current proposal, and find which proposal will be committed if we reach a commit on the current proposal
	b_array = hotstuff.get_qc_chain(b_new);

	b2 = b_array[2] //first phase, prepare
	b1 = b_array[1] //second phase, precommit
	b = b_array[0] //third phase, commit

	if (b_new.parent == b2 && b2.parent == b1) b_new.final_on_qc = b1;
	else b_new.final_on_qc = b1.parent.final_on_qc;

	b_new.proposal_id = hash(b_new.block_id, b_new.phase_counter, b_new.final_on_qc);

	return b_new;
}

//safenode predicate
hotstuff.is_node_safe(proposal){

	monotony_check = false;
	safety_check = false;
	liveness_check = false;
	commit_on_qc_check = false;

	b_array = hotstuff.get_qc_chain(proposal);

	b2 = b_array[2] //first phase, prepare
	b1 = b_array[1] //second phase, precommit
	b = b_array[0] //third phase, commit

	if (proposal.parent == b2 && b2.parent == b1) upcoming_commit = b1;
	else upcoming_commit = b1.parent.final_on_qc;

	//note : if we can't evaluate the QC chain upon activation or chain launch, we set commit_on_qc_check to true
	//abstracted [...]
	if (upcoming_commit == proposal.final_on_qc){
		commit_on_qc_check = true;
	}
	
	//Lemma 1
	if (proposal.get_height() > me._v_height){
		monotony_check = true;
	}

	if (me._b_lock){

		//Safety check : check if this proposal extends the proposal we're locked on
		if (hotstuff.extends(proposal, me._b_lock)){
			safety_check = true;
		}

		//Liveness check : check if the height of this proposal's justification is higher than the height of the proposal I'm locked on. This allows restoration of liveness if a replica is locked on a stale proposal
		if (proposal.justify.get_height() >  me._b_lock.get_height())){
			liveness_check = true;
		}

	}
	else { 

		//if we're not locked on anything, means the protocol just activated or chain just launched and we can proceed
		liveness_check = true;
		safety_check = true;
	}

	//Lemma 2
	return commit_on_qc_check && monotony_check && (liveness_check || safety_check); //return true if commit on QC check, monotony check and at least one of liveness or safety check evaluated successfully

}

//verify if b_descendant extends a branch containing b_ancestor
hotstuff.extends(b_descendant, b_ancestor){
		
	//in order to qualify as extending b_ancestor, b_descendant must descend from b_ancestor. This means that b_descendant.get_height() must necessarily be greater than b_ancestor.get_height()
	//however, we must also verify that b_ancestor.block_id exists in the blockchain containing b_descendant.block_id.
	//abstracted [...]

	return true || false;

}

//creates or get, then return the current QC for this block candidate
hotstuff.create_or_get_qc(proposal){
	
	//retrieve from or create and store unique QC for this proposal. Primary key for storage is proposal_id 
	//abstracted [...]

	return qc; // V[]

}

//add a signature to a QC
hotstuff.add_to_qc(qc, finalizer, sig){
	
	//update QC reference

	if (get_finalizers().contains(finalizer) && !qc.sig_bitset.contains(finalizer)){
		qc.sig_bitset += finalizer;
		qc.agg_sig += sig; //signature aggregation
	}
	
}

//when we receive a proposal
hotstuff.on_proposal_received(msg){
	
	//block candidate validation (check if block is valid, etc.), return if not 
	//abstracted [...]

	am_i_finalizer = get_finalizers().contains(me);

	me._b_storage.add(msg.proposal); //new proposal 

	//if I am a finalizer for this proposal and allowed to sign, test safenode predicate for possible vote
	if (am_i_finalizer && hotstuff.is_node_safe(msg.proposal)){
		
		me._v_height = msg.proposal.get_height();

		/* 

			Sign message.	

			In Hotstuff, we need to sign a tuple of (msg.view_type, msg.view_number and msg.node).

			In our implementation, we define proposal_id as the message replicas sign, which is a digest of the tuple (block_id, phase_counter, final_on_qc).

		*/

		sig = <signature over msg.proposal.proposal_id>;  //abstracted [...]

		finalizer = me;

		//Lemma 4
		msg = new_message(vote, msg.proposal.proposal_id, sig, finalizer); //cast my vote

		network_plugin.broadcast(msg); //broadcast message
		
	}

	hotstuff.update(msg.proposal);

	//if we are not expecting any additional proposal for the current leader's round, we can call pacemaker.on_leader_rotate() here
	//corresponds to condition #1 of onNextSyncView comment
	//abstracted [...]

}

//when leader receives a vote on a proposal
hotstuff.on_vote_received(msg){
	
	//check for duplicate or invalid vote, return in either case
	//abstracted [...]

	am_i_leader = get_leader() == me; //am I leader?

	if(!am_i_leader) return;

	//only leader need to take action on votes

	qc = hotstuff.create_or_get_qc( msg.proposal); //create or get the qc for this proposal

	hotstuff.add_to_qc(qc, msg.finalizer, msg.sig);

	if (qc.quorum_met()){
	
		pacemaker.update_high_qc(qc);

		//if we're operating in event-driven mode and the proposal hasn't reached the decide phase yet
		if (me._chained_mode==false && msg.proposal.phase_counter<3){

			msg.proposal.phase_counter++; //increment phase_counter for proposal

			on_beat(msg.proposal); //call on_beat with updated proposal

		}

	}

}

//internal state update of replica
hotstuff.update(proposal){
	
	b_new = proposal;

	b_array = hotstuff.get_qc_chain(proposal);

	b2 = b_array[2] //first phase, prepare
	b1 = b_array[1] //second phase, precommit
	b = b_array[0] //third phase, commit

	//precommit phase on b2
	pacemaker.update_high_qc(proposal.justify);

	if (b1.get_height() > me._b_lock.get_height()){
		me._b_lock = b1; //commit phase on b1
	}

	//direct parent relationship verification 
	if (b2.parent == b1 && b1.parent == b){
		
		hotstuff.commit(b);
		
		me._b_exec = b; //decide phase on b

	}

}

//commit block and execute its actions against irreversible state
hotstuff.commit(proposal){

	//check if proposal already committed, if so, return because there is nothing to do

	//can only commit newer blocks
	if (me._b_exec.get_height() < proposal.get_height()){
		
		parent_b = _b_storage.get(proposal.parent.proposal_id);

		hotstuff.commit(parent_b); //recursively commit all non-committed ancestor blocks sequentially first

		//execute block actions
		//abstracted [...]

	}
}


/*

	Proofs :

	Safety :

		Lemma 1. Let b and w be two conflicting proposals such that b.get_height() = w.get_height(), then they cannot both have valid quorum certificates.

		Proof. Suppose they can, so both b and w receive 2f + 1 votes, among which there are at least f + 1 honest replicas voting for each proposal, then there must be an honest replica that votes for both, which is impossible because b and w are of the same height.

		This is enforced by the monotony check of the code block labeled "Lemma 1", which prevents honest replicas from casting two votes for the same proposal height. 

		Lemma 2. Let b and w be two conflicting proposals. Then they cannot both become committed, each by an honest replica.

		Proof. We prove this lemma by contradiction. Let b and w be two conflicting proposals at different heights.
		
		Assume during an execution, b becomes committed at some honest replica via the QC Three-Chain b.

		For this to happen, b must be the parent and justification of b1, b1 must be the parent and justification of b2 and b2 must be the justification of a new proposal b_new.

		Likewise w becomes committed at some honest replica via the QC Three-Chain w.

		For this to happen, w must be the parent and justification of w1, w1 must be the parent and justification of w2 and w2 must be the justification of a new proposal w_new.

		By lemma 1, since each of the proposals b, b1, b2, w, w1, w2 have QCs, then without loss of generality, we assume b.get_height() > w2.get_height().

		We now denote by qc_s the QC for a proposal with the lowest height larger than w2.get_height(), that conflicts with w.

		Assuming such qc_s exists, for example by being the justification for b1. Let r denote a correct replica in the intersection of w_new.justify and qc_s. By assumption of minimality of qc_s, the lock that r has on w is not changed before qc_s is formed. Now, consider the invocation of on_proposal_received with a message carrying a conflicting proposal b_new such that b_new.block_id = qc_s.block_id. By assumption, the condition on the lock (see line labeled "Lemma 2") is false.

		On the other hand, the protocol requires t = b_new.justifty to be an ancestor of b_new. By minimality of qc_s, t.get_height() <= w2.get_height(). Since qc_s.block_id conflicts with w.block_id, t cannot be any of w, w1 or w2. Then, t.get_height() < w.get_height() so the other half of the disjunct is also false. Therefore, r will not vote for b_new, contradicting the assumption of r.

		Theorem 3. Let action_1 and action_2 be any two commands where action_1 is executed before action_2 by some honest replica, then any honest replica that executes action_2 must execute cm1 before action_2.

		Proof. Denote by w the node that carries action_1, b carries action_2. From Lemma 1, it is clear the committed nodes are at distinct heights. Without loss of generality, assume w.get_height() < b.get_height(). The commitment of w and b are handled by commit(w1) and commit(b1) in update(), where w is an ancestor of w1 and b is an ancestor of b1. According to Lemma 2, w1 must not conflict with b1, so w does not conflict with b. Then, w is an ancestor of b, and when any honest replica executes b, it must first execute w by the recursive logic in commit().

	Liveness :

		In order to prove liveness, we first show that after GST, there is a bounded duration T_f such that if all correct replicas remain in view v during T_f and the leader for view v is correct, then a decision is reached. We define generic_qc_1 and generic_qc_2 as matching QCs if generic_qc_1 and generic_qc_2 are both valid, and hotstuff.extends(generic_qc_2, generic_qc_1) = true.

		Lemma 4. If a correct replica is locked such that me._b_lock.justify = generic_qc_2, then at least f + 1 correct replicas voted for some generic_qc_1 matching me._b_lock.justify.

		Proof. Suppose replica r is locked on generic_qc_2. Then, (n-f) votes were cast for the matching generic_qc_1 in an earlier phase (see line labeled "Lemma 4"), out of which at least f + 1 were from correct replicas.

		Theorem 5. After GST, there exists a bounded time period T_f such that if all correct replicas remain in view v during T_f and the leader for view v is correct, then a decision is reached.

		Proof. Starting in a new view, the leader has collected (n − f) new_view or vote messages and calculates its high_qc before broadcasting a QC message. Suppose among all replicas (including the leader itself), the highest kept lock is me._b_lock.justify = generic_qc_new_2.

		By Lemma 4, we know there are at least f + 1 correct replicas that voted for a generic_qc_new_1 matching generic_qc_new_2, and have already sent them to the leader in their new_view or vote messages. Thus, the leader must learn a matching generic_qc_new_2 in at least one of these new_view or vote messages and use it as high_qc in its initial QC message for this view. By the assumption, all correct replicas are synchronized in their view and the leader is non-faulty. Therefore, all correct replicas will vote at a specific height, since in is_node_safe(), the condition on the line labeled "Liveness check" is satisfied. This is also the case if a proposal conflicts with a replica’s stale me._b_lock.justify, such that the condition on the line labeled "Safety check" is evaluated to false. 

		Then, after the leader has a valid generic_qc for this view, all replicas will vote at all the following heights, leading to a new commit decision at every step. After GST, the duration T_f for the steps required to achieve finality is of bounded length.

		The protocol is Optimistically Responsive because there is no explicit “wait-for-∆” step, and the logical disjunction in is_node_safe() is used to override a stale lock with the help of the Three-Chain paradigm.

		In order to ensure that the protocol keeps progressing even in the presence of a faulty leader, the pacemaker algorithm currently uses the existing Antelope schedule consensus mechanism, where leader rotation occurs at each interval of (_block_interval * _blocks_per_round). Selection is part of the consensus, and follows canonical schedule ordering, typically following alphabetical producer name or numerical location ordering. However, a new pacemaker algorithm can be defined as part of a future upgrade if desired, without breaking the safety of the protocol.


	Accountability and finality violation :

		Let us define b_2 as a proposal descendant of a b_0 proposal, such that hotstuff.extends(b_2, b_0) returns true.

		Suppose b_2.justify is b_1, and that b_1.justify is b_0. When we become aware of a new proposal where justify is a valid QC pointing to b_2, we know b_0, as well as all of b_0's ancestors, have been committed and are final.

		Theorem 6. Let b_2 and w_2 be two conflicting proposals of the same height, such that hotstuff.extends(b_2, w_2) and hotstuff.extends(w_2, b_2) both return false, and that b_2.get_height() == w_2.get_height(). Then they cannot each receive a valid quorum certificate without causing a finality violation on b_0 and w_0. In the case of such finality violation, any party in possession of a proposal with a QC justification pointing to b_2 and of a proposal with a QC justification pointing to w_2 would be able to prove complicity of block finalizers having taken part in this finality violation, as well as exonerate block finalizers having not taken part in the finality violation.

		Proof. Let b_2 and w_2 be descendants of respectively b_0 and w_0, such that hotstuff.extends(b_2, b_0) and hotstuff.extends(w_2, w_0) both return true. Let b_2.justify = b_1, b_1.justify = b_0, and w_2.justify = w_1, w_1.justify = w_0. 

		By Lemma 1, we know that a correct replica cannot sign two conflicting proposal candidates at the same height.

		Suppose we hold proposals b_new and w_new, where b_new.justify = b_2 and w_new.justify = w_2, we can identify and verify the signatures of finalizers, by ensuring the justification's agg_sig matches the aggregate key calculated from the sig_bitset and the schedule.

		Therefore, for b_2 and w_2 to both be included as a QC justification into descendant blocks b_new and w_new, at least one correct replica must have signed two vote messages on conflicting block candidates at the same height, which is impossible due to the checks performed in the function with comment "Lemma 1". Such an event would cause a finality violation on b_0 and w_0.

		For a finality violation to occur, the intersection of the finalizers that have voted for both b_2 and w_2, as evidenced by b_new.justify = b_2 and w_new.justify = w_2 must represent a minimum of f + 1 faulty nodes.

		By holding otherwise valid proposals where a QC for b_2 and w_2 exist, the finality violation on b_0 and w_0 can be proved trivially, simply by calculating the intersection and the symmetrical difference of the finalizer sets having voted for these two proposals. The finalizers contained in the intersection can therefore be blamed for the finality violation. The symmetric difference of finalizers that have voted for either proposal but not for both can be exonerated from wrong doing, thus satisfying the Accountability property requirement.


	Light client proof verification

		In order to facilitate the verification of finality by light clients, a proposal also includes a final_on_qc field, which is a reference to another proposal that is guaranteed to be commited if the current proposal reaches quorum.

		For an honest replica to sign a proposal, it must be able to verify that the final_on_qc proposal would be committed if the current proposal reaches quorum, in addition to all other required verifications on the current proposal.

		This additional rule doesn't impact safety, because all proposals that would previously fail the safenode predicate and monotony check would still fail. We we are only adding one more possible restriction, and not removing or relaxing any of the existing ones. Therefore, existing safety guarantees are maintained.

		This additional rule doesn't impact liveness either, since an honest leader that is out of sync, and therefore unable to provide the correct final_on_qc proposal would also be unable to produce a correct proposal that would pass the monotony check of finalizers.

		Since a correct replica would only sign a proposal if the final_on_qc was guaranteed to be executed upon the proposal reaching quorum, a QC over a proposal containing final_on_qc is therefore a proof of finality for the block referred to by the final_on_qc and all of its ancestors. This proof can be verified by a light client with a single signature verification.


*/



